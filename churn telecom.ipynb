{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape(3333, 18)\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    'state',\n",
    "    'account length', \n",
    "    'area code', \n",
    "    'phone number', \n",
    "    'international plan', \n",
    "    'voice mail plan', \n",
    "    'number vmail messages',\n",
    "    'total day minutes',\n",
    "    'total day calls',\n",
    "    'total day charge',\n",
    "    'total eve minutes',\n",
    "    'total eve calls',\n",
    "    'total eve charge',\n",
    "    'total night minutes',\n",
    "    'total night calls',\n",
    "    'total night charge',\n",
    "    'total intl minutes',\n",
    "    'total intl calls',\n",
    "    'total intl charge',\n",
    "    'number customer service calls',\n",
    "    'churn']\n",
    "\n",
    "df = pd.read_csv('churn.data.txt', header=None, names=columns)\n",
    "mapping = {'no': 0., 'yes':1., 'False.':0., 'True.':1.}\n",
    "df.replace({'international plan' : mapping, 'voice mail plan' : mapping, 'churn':mapping}, regex=True, inplace=True)\n",
    "\n",
    "df.drop('phone number', axis=1, inplace=True)\n",
    "df.drop('area code', axis=1, inplace=True)\n",
    "df.drop('state', axis=1, inplace=True)\n",
    "\n",
    "print(\"Dataset shape\" + str(df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    483\n",
       "0.0    400\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the dataset\n",
    "d_1 = df[df['churn']==1] #churned users\n",
    "d_2 = df[df['churn']==0] #loyal users\n",
    "\n",
    "df = d_1.append(d_2[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train - test 90% 10%\n",
    "X = df.loc[:, df.columns != 'churn']\n",
    "Y = df['churn']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#churn or not churn\n",
    "nb_classes = 1 \n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#scale the inputs for NN\n",
    "scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "scaler.fit(X)\n",
    "\n",
    "XX_train = scaler.transform(X_train.values)\n",
    "XX_test  = scaler.transform(X_test.values) #changing the shape of the distribution\n",
    "\n",
    "YY_train = Y_train.values \n",
    "YY_test  = Y_test.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794, 17) (794,)\n",
      "(89, 17) (89,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, YY_train.shape)\n",
    "print (X_test.shape, YY_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 epochs, gradient batched each 100 samples\n",
    "\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few Defination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sequential -  linear stack of layers.\n",
    "\n",
    "specifying the input shape\n",
    "Activations - Before training a model you need to configure the learning process using compile \n",
    "when choosing an optimizer consider the depth of your network and how quickly you get your results\n",
    "\n",
    "Optimizers - Optimisation functions usually calculate the gradient i.e. the partial derivative of loss function \n",
    "with respect to weights, and the weights are modified in the opposite direction of the calculated gradient.\n",
    "This cycle is repeated until we reach the minima of loss function.\n",
    "a non liner layer employed to the summation of the linear layer in this case we use sigmoid to \n",
    "restric the results between 0 and 1, others Relu, tahn, leaky Relu\n",
    "\n",
    "Relu- non-linear function. It gives an output x if x is positive and 0 otherwise.\n",
    "\n",
    "Loss - loss function is how you are penalizing you output, the magnitude of error your model made on the output so\n",
    "that you can adjust your weights e.g mean squared error (L2), mean absolute error(L1), cross entrophy done\n",
    "using backprop\n",
    "\n",
    "BatchNormalization - normalise the inputs of each layer in such a way that they have a mean output activation of zero \n",
    "and standard deviation of one. speed up learning. Deals with change in distribution \n",
    "\n",
    "Dropout -refers to dropping out units (both hidden and visible) in a neural network. Not considered during a particular forward or \n",
    "backward pass. prevents overfiting.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(17,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(50, input_shape=(17,)))\n",
    "# model.add(Activation(\"hard_sigmoid\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation(\"hard_sigmoid\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# model.fit(XX_test, YY_test, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(XX_test, YY_test) #ealuating the models accuracy or loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 609\n",
      "Trainable params: 609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7872681798559896, 0.5168539342585574]\n"
     ]
    }
   ],
   "source": [
    "#This can be improved\n",
    "print (score) #ealuating the models accuracy and loss\n",
    "\n",
    "#59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot2.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
